{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando Bibliotecas Importantes"
      ],
      "metadata": {
        "id": "x7frmGiA2Gnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pXC60IQ1-0O"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando Principais Bibliotecas"
      ],
      "metadata": {
        "id": "GQMXqENB2Jk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import MobileNet_V3_Large_Weights\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.serialization\n",
        "import torchmetrics\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "XWlbFgX02JTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixando seed"
      ],
      "metadata": {
        "id": "XZIibzZi2Pzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.random.manual_seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "mA-zmt-J2Obd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montando Drive com o dataset"
      ],
      "metadata": {
        "id": "gnUD5Khc2Rc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "data = '/content/drive/MyDrive/DatasetPlacas_WandersonJunior'"
      ],
      "metadata": {
        "id": "uEKCneLu2Tuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando arquivo de anotações em csv e associação de classe numérica com string\n",
        "- Cada linha do csv contém como colunas o nome da imagem e sua label correspondente\n",
        "\n",
        "- As classes foram convertidas da seguinte forma:\n",
        "\n",
        "```\n",
        "R-1:   0\n",
        "A-18:  1\n",
        "A-32:  2\n",
        "R-6a:  3\n",
        "R-3:   4\n",
        "```"
      ],
      "metadata": {
        "id": "A2WZWdUD2U-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv = []\n",
        "class_csv = []\n",
        "\n",
        "\n",
        "for id, classname in enumerate(os.listdir(data)):\n",
        "  class_csv.append([classname,id])\n",
        "  classe_imgs = os.path.join(data,classname)\n",
        "  if os.path.isdir(classe_imgs):\n",
        "    for img_name in os.listdir(classe_imgs):\n",
        "      data_csv.append([img_name, id])\n",
        "\n",
        "df_class = pd.DataFrame(class_csv,columns=['classname','id'])\n",
        "df_class.to_csv('/content/drive/MyDrive/DatasetPlacas_WandersonJunior/class_idx.csv',index=False)\n",
        "df = pd.DataFrame(data_csv,columns=['filename','label'])\n",
        "df.to_csv('/content/drive/MyDrive/DatasetPlacas_WandersonJunior/labels.csv',index=False)"
      ],
      "metadata": {
        "id": "MVR4Bt062W5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DatasetPlacas_WandersonJunior/labels.csv')"
      ],
      "metadata": {
        "id": "21UpCjGa2Z2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data ='/content/drive/MyDrive/data'"
      ],
      "metadata": {
        "id": "Ad32UNKq2bQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando Classe Dataset\n",
        "- que lê as imagens do dataset dentro de uma pasta /data e as anotações dentro do arquivo /labels.csv"
      ],
      "metadata": {
        "id": "bRHBqpBf2cm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlacasDataset(Dataset):\n",
        "  def __init__(self, img_dir, label_file, transform=None):\n",
        "    self.labels = label_file\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir, self.labels.iloc[idx,0])\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    label = self.labels.iloc[idx, 1]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "S8Hs8xt62ex4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando transformações nas imagens\n",
        "  - redução das imagens para um tamanho padronizado (para caber na gpu)\n",
        "  - Aplicação de rotações, translações e ruido gaussiano\n",
        "  - Aplicação da normalização no final baseado na normalização da ImageNet"
      ],
      "metadata": {
        "id": "rx--x-n32ghs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512,512)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(5)],p=0.3),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "yTCrTR0e2iaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação em treino, teste e validação\n",
        "- pego o dataframe criado a partir do csv de anotações e particiono ele em 3 dataframes com 60% dos dados no dataframe de treino, 20% no de teste e 20% no de validação"
      ],
      "metadata": {
        "id": "opGrxYod2jsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "total = len(df)\n",
        "train_end = int(0.6 * total)\n",
        "val_end = train_end + int(0.2 * total)\n",
        "\n",
        "df_train = df[:train_end]\n",
        "df_val   = df[train_end:val_end]\n",
        "df_test  = df[val_end:]\n",
        "\n",
        "train = PlacasDataset(data,df_train,transform)\n",
        "val = PlacasDataset(data,df_val,transform)\n",
        "test = PlacasDataset(data,df_test,transform)\n"
      ],
      "metadata": {
        "id": "nJb1JY_K2lLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loop de treino\n",
        "- roda o loop de treino padrão do pytorch com validação em todas as épocas\n",
        "- métrica de treino f1-score\n",
        "- salva modelo com melhor f1-score na validação"
      ],
      "metadata": {
        "id": "MsSD5vVf2mmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_Classifier(model, epochs, optimizer, criterion, scheduler, f1,train,val,train_losses, val_losses):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = model.to(device)\n",
        "  score = 0.0\n",
        "\n",
        "  trainloader = DataLoader(train,batch_size=8,num_workers=2)\n",
        "  valloader = DataLoader(val,batch_size=1,num_workers=2)\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    trainloss = 0\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        img, label = data\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(img)\n",
        "        loss = criterion(outputs,label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step(loss)\n",
        "\n",
        "        trainloss += loss.item()\n",
        "\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}/{epochs}, Batch {i}] Loss: {trainloss:.4f} | LR: {lr:.6f}\")\n",
        "\n",
        "    loss_avg = trainloss / len(trainloader)\n",
        "    print(f\"loss_avg: {loss_avg:.4f}\")\n",
        "\n",
        "    train_losses.append(loss_avg)\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      f1.reset()\n",
        "      for img_val, label_val in valloader:\n",
        "        img_val = img_val.to(device)\n",
        "        label_val = label_val.to(device)\n",
        "        outputs = model(img_val)\n",
        "\n",
        "        indexes, predicao = torch.max(outputs, 1)\n",
        "\n",
        "        f1.update(predicao, label_val)\n",
        "\n",
        "        loss_val = criterion(outputs, label_val)\n",
        "\n",
        "        val_loss += loss_val.item()\n",
        "\n",
        "      final_f1 = f1.compute()\n",
        "\n",
        "      print(f\"f1 score de validação: {final_f1.item():.4f}\")\n",
        "      print(f\"val_loss: {val_loss:.4f}\")\n",
        "\n",
        "      val_loss_avg = val_loss / len(valloader)\n",
        "      val_losses.append(val_loss_avg)\n",
        "\n",
        "      if score < final_f1:\n",
        "        score = final_f1\n",
        "        torch.save(model, f\"/content/drive/MyDrive/Resultados/melhor_modelo_{epoch}.pth\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      model.train()"
      ],
      "metadata": {
        "id": "2nWOnyBG2oVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do modelo para treino\n",
        "- Ajusta a MobileNet para classificação de 5 classes\n",
        "- define épocas de treino\n",
        "- otimizador: AdamW\n",
        "- Scheduler: OneCycleLR"
      ],
      "metadata": {
        "id": "phh2Lznv2qCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = MobileNet_V3_Large_Weights.DEFAULT\n",
        "model = torchvision.models.mobilenet_v3_large(weights=weights)\n",
        "model.classifier[-1] = nn.Linear(1280, 5)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "epochs = 30\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "scheduler = OneCycleLR(optimizer,\n",
        "                       max_lr=1e-3,\n",
        "                       total_steps=(len(train)//8) * 30)\n",
        "\n",
        "f1 = torchmetrics.F1Score('multiclass', num_classes=5,average='macro').to(device)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_Classifier(model, epochs, optimizer, loss, scheduler,f1, train,val,train_losses,val_losses)"
      ],
      "metadata": {
        "id": "r_nFAav02s4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotagem das Curvas de Loss de Treino e Validação"
      ],
      "metadata": {
        "id": "dxsh-6kW23vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss durante o Treinamento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B8vgtsiR2xut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inferência\n",
        "\n",
        "Cálculo das métricas f1-score macro, accuracy e precision para o conjunto de teste com o melhor modelo obtido no treino"
      ],
      "metadata": {
        "id": "ORZn92uB21YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"/content/drive/MyDrive/Resultados/melhor_modelo_10.pth\", weights_only=False)\n",
        "\n",
        "accuracy = torchmetrics.Accuracy('multiclass',num_classes=5).to(device)\n",
        "precision = torchmetrics.Precision('multiclass',num_classes=5).to(device)\n",
        "\n",
        "f1.reset()\n",
        "accuracy.reset()\n",
        "precision.reset()\n",
        "\n",
        "\n",
        "testloader = DataLoader(test,batch_size=1,num_workers=2)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image_test, label_test in testloader:\n",
        "    image = image_test.to(device)\n",
        "    label = label_test.to(device)\n",
        "\n",
        "    outputs = model(image)\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    f1.update(preds,label)\n",
        "    accuracy.update(preds,label)\n",
        "    precision.update(preds,label)\n",
        "\n",
        "\n",
        "f1_test = f1.compute()\n",
        "accuracy_test = accuracy.compute()\n",
        "precision_test = precision.compute()\n",
        "\n",
        "print(f\"F1-Score: {f1_test}\")\n",
        "print(f\"Acurácia: {accuracy_test}\")\n",
        "print(f\"Precision: {precision_test}\")"
      ],
      "metadata": {
        "id": "mM3lX72Q20hg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}